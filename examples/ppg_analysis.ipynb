{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__BIOBSS - A python package for biological signal processing by OBSS__\n",
    "\n",
    "_This package includes modules to process PPG, EDA and ACC signals recorded using wearable devices._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import BIOBSS and the other required packages\n",
    "\n",
    "import biobss\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#help(biobss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook includes guidelines to help using the package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1.[Pipeline for formatting Empatica data files](#empatica)<br>\n",
    "2.[Pipeline for formattion Polar Verity Sense data files](#polar)<br>\n",
    "3.[Load the sample data](#sampledata)<br>\n",
    "4.[PPG signal preprocessing pipeline](#ppg_pre)<br>\n",
    "5.[PPG signal quality assessment pipeline](#ppg_sqa)<br>\n",
    "6.[Respiratory rate estimation pipeline](#ppg_rr)<br>\n",
    "7.[Calculation of PPG features](#ppg_features)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Pipeline for formatting Empatica data files__\n",
    "<a id=\"empatica\"></a>\n",
    "_If the data was recorded using an Empatica device, the methods below can be used to extract the required data files from the zip archive and correct for the time format._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the file paths for the zip files, temporary files and csv files (For Empatica file extraction and time-format correction)\n",
    "zipfiles_dir=\"C:\\\\Users\\\\ipek.karakus\\\\Desktop\\\\biobss\\\\Empatica_files\\\\zip_files\\\\\"\n",
    "temp_dir=\"C:\\\\Users\\\\ipek.karakus\\\\Desktop\\\\biobss\\\\Empatica_files\\\\temp\"\n",
    "csvfiles_dir=\"C:\\\\Users\\\\ipek.karakus\\\\Desktop\\\\biobss\\\\Empatica_files\\\\csv_files\"\n",
    "\n",
    "#Define the name of the zip file (record id)\n",
    "zip_file_name=\"1555678143_A01BC1.zip\"\n",
    "\n",
    "#This method first extracts the csv files from the zip archive to a temporary folder. Then, the files are renamed and moved into the final directory.\n",
    "biobss.signaltools.e4_format.unzip_and_rename(zipfiles_dir, temp_dir, csvfiles_dir, zip_file_name)\n",
    "\n",
    "#Define the filename and filesource for timestamp correction.\n",
    "theid = '1555678143_A01BC1' #This is the subject ID number (name of file)\n",
    "filesource = \"C:\\\\Users\\\\ipek.karakus\\\\Desktop\\\\biobss\\\\Empatica_files\\\\csv_files\\\\\" #This is the source folder that contains all of your participant folders\n",
    "\n",
    "#Different methods are used to correct the timestamp since the content of each csv file depends on the type of signal. \n",
    "os.chdir(r'C:\\Users\\ipek.karakus\\Desktop\\biobss\\Empatica_files\\csv_files')\n",
    "#Correct timestamp for EDA, TEMP, HR and BVP signal files.\n",
    "listtyped = ['EDA','TEMP', 'HR','BVP'] \n",
    "[biobss.signaltools.e4_format.importandexport(filesource, theid, typed) for typed in listtyped]\n",
    "#Correct timestamp for ACC signal files.\n",
    "biobss.signaltools.e4_format.importandexportAcc(filesource, theid, 'ACC') \n",
    "#Correct timestamp for IBI signal files.\n",
    "biobss.signaltools.e4_format.importandexportIBI(filesource, theid, 'IBI') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Pipeline for formatting Polar Verity Sense data files__\n",
    "<a id=\"polar\"></a>\n",
    "_If the data was recorded using a Polar device, the methods below can be used to save data files as csv file and and synchronize the signal from different sensors._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the file paths for the files\n",
    "txt_dir=\"C:\\\\Users\\\\ipek.karakus\\\\Desktop\\\\biobss\\\\Polar_files\\\\txt_files\\\\\"\n",
    "csv_dir=\"C:\\\\Users\\\\ipek.karakus\\\\Desktop\\\\biobss\\\\Polar_files\\\\csv_files\\\\\"\n",
    "pkl_dir=\"C:\\\\Users\\\\ipek.karakus\\\\Desktop\\\\biobss\\\\Polar_files\\\\pkl_files\\\\\"\n",
    "\n",
    "#Txt files can be saved as csv files\n",
    "biobss.reader.polar_format.txt_to_csv(txt_dir)\n",
    "\n",
    "#Timestamps in iso format can be converted to milliseconds for a specific file. This can be done by referencing either to start time of the sensor or a given start time.\n",
    "filepath=r'C:\\Users\\ipek.karakus\\Desktop\\biobss\\Polar_files\\csv_files\\ik_d1_25042022_forearm_left\\Polar_Sense_A40F6F28_20220425_113903_PPG.csv'\n",
    "df= pd.read_csv(filepath)\n",
    "time_msec=biobss.reader.polar_format.timestamp_to_msec(df['Phone timestamp']) \n",
    "\n",
    "#If required, the selected csv files can be updated by adding a 'Time_record (ms)' column, corresponds to time points in ms. The timepoints are calculated referenced to the earliest timestamp for all sensors.\n",
    "csv_subdir=\"C:\\\\Users\\\\ipek.karakus\\\\Desktop\\\\biobss\\\\Polar_files\\\\csv_files\\\\ik_d1_25042022_forearm_left\" #This time, the path should be defined for a specific record.\n",
    "biobss.reader.update_csv(csv_dir=csv_subdir,marker=True)\n",
    "\n",
    "#For synchronization of the signals, a common (overlapping region for all sensors) time array can be generated. This time, the path should be defined for a specific record.\n",
    "time_list=biobss.reader.calculate_sync_time(csv_dir=csv_subdir,time_step=1,marker=True)\n",
    "\n",
    "#If required, the time array can be saved as a txt file.\n",
    "time_list=biobss.reader.calculate_sync_time(csv_dir=csv_subdir,time_step=1,marker=True,save_file=True)\n",
    "\n",
    "#The signals can be synchronized by interpolating the signal for the given time_list.\n",
    "data=biobss.reader.synchronize_signals(csv_subdir,time_list)\n",
    "\n",
    "#Resampling can be applied if the required parameters (sampling_rate and resampling_rate are given) \n",
    "data=biobss.reader.synchronize_signals(csv_subdir,time_list,resampling_rate=100)\n",
    "\n",
    "#If required, the synchronized signals can be saved as a csv file.\n",
    "data=biobss.reader.synchronize_signals(csv_subdir,time_list,resampling_rate=100,save_files=True)\n",
    "\n",
    "#The synchronized signals can be segmented for events\n",
    "filepath=r'C:\\Users\\ipek.karakus\\Desktop\\biobss\\Polar_files\\csv_files\\ik_d1_25042022_forearm_left\\sync_ACC_PPG_MAGN_GYRO.csv'\n",
    "markerpath=r'C:\\Users\\ipek.karakus\\Desktop\\biobss\\Polar_files\\csv_files\\ik_d1_25042022_forearm_left\\MARKER_20220425_114002.csv'\n",
    "out_path=r'C:\\Users\\ipek.karakus\\Desktop\\biobss\\Polar_files\\csv_files\\ik_d1_25042022_forearm_left\\event_list.txt'\n",
    "data=biobss.reader.segment_events(filepath,markerpath,['rest'],out_path)\n",
    "\n",
    "#The event list can also be saved as txt file for later use\n",
    "biobss.reader.segment_events(filepath,markerpath,['rest'],out_path,save_file=True)\n",
    "\n",
    "#Csv file can be read into a dictionary\n",
    "filepath=r'C:\\Users\\ipek.karakus\\Desktop\\biobss\\Polar_files\\csv_files\\ik_d1_25042022_forearm_left\\Polar_Sense_A40F6F28_20220425_113903_PPG.csv'\n",
    "data=biobss.reader.polar_csv_reader(filepath,signal_type='PPG')\n",
    "\n",
    "#Csv files can be saved as pkl files\n",
    "biobss.reader.csv_to_pkl(csv_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Load the sample data__\n",
    "<a id=\"sampledata\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the sample data\n",
    "\n",
    "data_dir=r'C:\\Users\\ipek.karakus\\Desktop\\biobss\\sample_data'\n",
    "\n",
    "filename='ieee_wearable_P1_ppg.csv'\n",
    "\n",
    "data=biobss.signaltools.load_csv(data_dir,filename)\n",
    "sig=np.asarray(data.iloc[0,:])\n",
    "fs=64\n",
    "L=10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __PPG Signal Preprocessing Pipeline__\n",
    "<a id=\"ppg_pre\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PPG signals can be filtered using the method below using pre-determined filter parameters\n",
    "\n",
    "filtered_ppg=biobss.ppgtools.filter_ppg(sig,fs)\n",
    "\n",
    "#or defining the parameters.\n",
    "\n",
    "f_sig= biobss.signaltools.filter_signal(sig,'bandpass',2,fs,f1=0.5,f2=5)\n",
    "\n",
    "#Signal peaks can be detected as below\n",
    "\n",
    "info=biobss.signaltools.peakdetection.peak_detection(sig,fs,'peakdet',delta=0.01)\n",
    "\n",
    "locs_peaks=info['Peak_locs']\n",
    "peaks=info['Peaks']\n",
    "locs_onsets=info['Trough_locs']\n",
    "onsets=info['Troughs']\n",
    "\n",
    "#and the results can be corrected considering the order of peaks and onsets\n",
    "info=biobss.ppgtools.peak_control(locs_peaks,peaks,locs_onsets,onsets)\n",
    "\n",
    "locs_peaks=info['Peak_locs']\n",
    "peaks=info['Peaks']\n",
    "locs_onsets=info['Trough_locs']\n",
    "onsets=info['Troughs']\n",
    "\n",
    "#If needed, first and second derivatives of the signal can be calculated using the method below.\n",
    "info=biobss.signaltools.derivation.ppg_derivation(sig)\n",
    "vpg_sig=info['VPG']\n",
    "apg_sig=info['APG']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __PPG Signal Quality Assessment Pipeline__\n",
    "<a id=\"ppg_sqa\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clipping and flatline detection can be done using the methods below\n",
    "#For clipping detection\n",
    "info=biobss.ppgtools.detect_flatline_clipping(sig,1.0)\n",
    "#For flatline detection\n",
    "info=biobss.ppgtools.detect_flatline_clipping(sig,0.0001,10)\n",
    "\n",
    "#The peaks should be detected for the following steps\n",
    "\n",
    "info=biobss.signaltools.peakdetection.peak_detection(sig,fs,'peakdet',delta=0.01)\n",
    "locs_peaks=info['Peak_locs']\n",
    "peaks=info['Peaks']\n",
    "locs_onsets=info['Trough_locs']\n",
    "onsets=info['Troughs']\n",
    "\n",
    "#and the results should be corrected considering the order of peaks and onsets\n",
    "info=biobss.ppgtools.peak_control(locs_peaks,peaks,locs_onsets,onsets)\n",
    "locs_peaks=info['Peak_locs']\n",
    "peaks=info['Peaks']\n",
    "locs_onsets=info['Trough_locs']\n",
    "onsets=info['Troughs']\n",
    "\n",
    "#Using the peak locations, the physiological and morphological limits can be checked\n",
    "\n",
    "info=biobss.ppgtools.check_phys(locs_peaks,fs)\n",
    "info=biobss.ppgtools.check_morph(locs_peaks,peaks,locs_onsets,onsets,fs)\n",
    "\n",
    "#Template matching method can be applied using the method below.\n",
    "\n",
    "info=biobss.ppgtools.template_matching(sig,locs_peaks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Respiratory Rate Estimation Pipeline__\n",
    "<a id=\"ppg_rr\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For respiratory rate estimation, the ppg signal should be filtered before extracting respiratory signal\n",
    "filt_sig=biobss.resptools.elim_vlf(sig,fs)\n",
    "filt_sig=biobss.resptools.elim_vhf(sig,fs)\n",
    "\n",
    "#Next, the PPG signal peaks and onsets are detected\n",
    "info=biobss.signaltools.peakdetection.peak_detection(sig,fs,'peakdet',delta=0.01)\n",
    "locs_peaks=info['Peak_locs']\n",
    "peaks=info['Peaks']\n",
    "locs_onsets=info['Trough_locs']\n",
    "onsets=info['Troughs']\n",
    "\n",
    "#In order to calculate the features correctly, the signal segment should start and end with an onset.  \n",
    "#Additionally, there should be a single peak between consecutive onsets.\n",
    "\n",
    "info=biobss.ppgtools.peak_control(locs_peaks,peaks,locs_onsets,onsets)\n",
    "locs_peaks=info['Peak_locs']\n",
    "peaks=info['Peaks']\n",
    "locs_onsets=info['Trough_locs']\n",
    "onsets=info['Troughs']\n",
    "\n",
    "#The next step is to extract the respiratory signal from the PPG signal.\n",
    "\n",
    "info=biobss.resptools.extract_resp_sig(locs_peaks,peaks,onsets,fs,['AM','FM','BW'],10)\n",
    "\n",
    "#The method above extracts the respiratory signals based on three modulation types seperately. To select the signal for a specific method.\n",
    "\n",
    "y_am=info['am_y']\n",
    "x_am=info['am_x']\n",
    "y_fm=info['fm_y']\n",
    "x_fm=info['fm_x']\n",
    "y_bw=info['bw_y']\n",
    "x_bw=info['bw_x']\n",
    "\n",
    "#If required, the extracted respiratory signal can be filtered prior to respiratory rate estimation.\n",
    "\n",
    "info=biobss.resptools.filter_resp_sig(resampling_rate=10, am_sig=y_am, am_x=x_am, fm_sig=y_fm, fm_x=x_fm, bw_sig=y_bw, bw_x=x_bw)\n",
    "\n",
    "y_am=info['am_sig']\n",
    "x_am=info['am_x']\n",
    "y_fm=info['fm_sig']\n",
    "x_fm=info['fm_x']\n",
    "y_bw=info['bw_sig']\n",
    "x_bw=info['bw_x']\n",
    "\n",
    "#If required, the respiratory quality assessment can be applied. Autocorrelation or Hjorth approaches can be used. \n",
    "#Note that, this step should be applied for a specific modulation type.\n",
    "\n",
    "rqi_am=biobss.resptools.calc_rqi(y_am,resampling_rate=10)\n",
    "rqi_fm=biobss.resptools.calc_rqi(y_fm,resampling_rate=10)\n",
    "rqi_bw=biobss.resptools.calc_rqi(y_bw,resampling_rate=10)\n",
    "\n",
    "#Now, the respiratory rate can be estimated. Note that, this method should be used for a specific modulation type.\n",
    "\n",
    "rr_am=biobss.resptools.estimate_rr(y_am,10,method='peakdet')\n",
    "rr_fm=biobss.resptools.estimate_rr(y_fm,10,method='peakdet')\n",
    "rr_bw=biobss.resptools.estimate_rr(y_bw,10,method='peakdet')\n",
    "\n",
    "#Seperate respiratory rates can be fused into a single value. SmartFusion method does not take RQIs into consideration.\n",
    "\n",
    "rr_fused=biobss.resptools.fuse_rr(fusion_method='SmartFusion', rqi=None, rr_am=rr_am, rr_fm=rr_fm, rr_bw=rr_bw)\n",
    "\n",
    "#In order to calculate the weighted average for fusion of RRs, the fusion_method should be selected as 'QualityFusion'.\n",
    "#RQIs (array) should be provided as a keyworded argument. The order of elements in the array should match with the order RRs of different modulation types.\n",
    "rqi=[rqi_am['hjorth'],rqi_fm['hjorth'],rqi_bw['hjorth']]\n",
    "rr_fused=biobss.resptools.fuse_rr(fusion_method='QualityFusion', rqi=rqi, rr_am=rr_am, rr_fm=rr_fm, rr_bw=rr_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Calculation of PPG features__\n",
    "<a id=\"ppg_features\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cycle-based features can be calculated\n",
    "ppg_cycle=biobss.ppgtools.extract_features.from_cycles(sig,locs_peaks,peaks,locs_onsets,onsets,fs,feature_types=['Time','Stat'],prefix='ppg')\n",
    "\n",
    "#Segment-based features can be calculated\n",
    "ppg_segment=biobss.ppgtools.extract_features.from_segment(sig,fs,feature_types=['Time','Stat','Freq'], prefix='ppg')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "caf79f27b4ac01d774e514259df884c26526df1a3a83479a23336fed20c7ab46"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
